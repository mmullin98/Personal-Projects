{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2092665",
   "metadata": {},
   "source": [
    "This works, but slow (4.2s per race)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68836c24",
   "metadata": {},
   "source": [
    "To do:\n",
    "- Fix place term errors\n",
    "- Automation at certain time?\n",
    "- Try optimise so its quicker\n",
    "- Define the whole function with input being todays urls, tomorrows urls or all urls\n",
    "- Misprice function needs work\n",
    "- Specify if a race is green, arb or misprice\n",
    "\n",
    "\n",
    "TO DO:\n",
    "- Fix mp definition\n",
    "- If one bookie doesn't have place terms it fails\n",
    "- Instead of having all bookies (spreadex) can we limit even further?\n",
    "- Email to say wether a race is green, arb or mp\n",
    "    - Further on, the green should say if its sky green or else green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ff825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import cfscrape\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import cloudscraper\n",
    "import pandas as pd\n",
    "from numpy import loadtxt\n",
    "from sendgrid import SendGridAPIClient\n",
    "from sendgrid.helpers.mail import Mail\n",
    "from datetime import datetime\n",
    "from random import randrange\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46650144",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e49348",
   "metadata": {},
   "source": [
    "book = [\"B3\", \"SK\", \"PP\", \"WH\", \"EE\", \"FB\", \"VC\", \"CE\", \"UN\", \"SX\", \"FR\", \"BY\", \"OE\", \"SA\", \"SI\", \"QN\", \"WA\", \"LD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c022962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: url\n",
    "# Output: Oddschecker table with horses and decimal prices\n",
    "# Working perfectly\n",
    "\n",
    "def getTable(url):\n",
    "\n",
    "    book = [\"B3\", \"SK\", \"PP\", \"WH\", \"EE\", \"FB\", \"VC\", \"CE\", \"UN\", \"SX\", \"FR\", \"BY\", \"OE\", \"SA\", \"SI\", \"QN\", \"WA\", \"LD\"]\n",
    "\n",
    "    ids = [\"diff-row evTabRow bc\"]\n",
    "\n",
    "    scraper = cloudscraper.create_scraper(delay=1,browser={'custom': 'ScraperBot/1.0',})\n",
    "\n",
    "    url = url\n",
    "\n",
    "    req = scraper.get(url)\n",
    "    soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "\n",
    "    data = soup.find(\"tbody\", {\"id\": \"t1\"})\n",
    "    all_horses = soup.find_all(\"tr\", {\"class\": ids})\n",
    "    num_horses = len(all_horses)\n",
    "\n",
    "    running_horses = []\n",
    "    i = 0\n",
    "    possible_nrs = 10\n",
    "    j = 0\n",
    "\n",
    "    while i < num_horses:\n",
    "        horse_name = all_horses[i]['data-bname']\n",
    "        running_horses.append(horse_name)\n",
    "        i+=1\n",
    "\n",
    "    while j < possible_nrs:\n",
    "        num = \"nr\"\n",
    "        running_horses.append(num)\n",
    "        j+=1\n",
    "\n",
    "    # b365 = data.find_all(\"td\", {\"data-bk\": \"B3\"})\n",
    "\n",
    "    # b365_prices = []\n",
    "    # l = 0 \n",
    "\n",
    "    # while l < len(b365):\n",
    "    #    price = b365[l]['data-odig']\n",
    "    #    b365_prices.append(price)\n",
    "    #    l+=1\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    df['horse'] = running_horses\n",
    "\n",
    "    gem = 0\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        while gem < len(book):\n",
    "            bookie = data.find_all(\"td\", {\"data-bk\": book[gem]})\n",
    "\n",
    "            prices = []\n",
    "            l = 0\n",
    "\n",
    "            while l < len(bookie):\n",
    "                price = bookie[l]['data-odig']\n",
    "                prices.append(price)\n",
    "                l+=1\n",
    "\n",
    "            df[book[gem]] = pd.Series(prices)\n",
    "            gem+=1\n",
    "\n",
    "        df = df[df.horse != 'nr']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e82d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: url (oddschecker table from getTable())\n",
    "# Output: Boolean (T/F) if any win overround is less than 100%\n",
    "# Working okay, not completely tested\n",
    "\n",
    "def checkArb(df):\n",
    "    book = [\"B3\", \"SK\", \"PP\", \"WH\", \"EE\", \"FB\", \"VC\", \"CE\", \"UN\", \"SX\", \"FR\", \"BY\", \"OE\", \"SA\", \"SI\", \"QN\", \"WA\", \"LD\"]\n",
    "    df = getTable(url)\n",
    "    all_winor = []\n",
    "    isarb = 0\n",
    "    i = 1\n",
    "    total_bookies = df.shape[1] - 1\n",
    "\n",
    "    # Get win overrounds for each bookie\n",
    "    while i <= total_bookies:\n",
    "\n",
    "        df[book] = df[book].apply(pd.to_numeric)\n",
    "\n",
    "        individual_book = df.iloc[:,i]\n",
    "\n",
    "        temp_df = pd.DataFrame(individual_book)\n",
    "\n",
    "        temp_df['prob'] = 1/temp_df.iloc[:,0]\n",
    "\n",
    "        win_or = round(temp_df['prob'].sum()*100,2)\n",
    "\n",
    "        all_winor.append(win_or)\n",
    "\n",
    "        i+=1\n",
    "\n",
    "        \n",
    "    # Check if any element in the win overrounds is less than 100%\n",
    "    isarb = all(i < 100 for i in all_winor)\n",
    "\n",
    "    return isarb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d3b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: An individual bookies prices (decimal), place terms (usually 4 or 5), places_paying (any number from 1 to 8)\n",
    "# Output: Boolean (T/F) if any place overround is less than the places_paying (i.e green book)\n",
    "# Working okay, not fully tested\n",
    "\n",
    "def getPlaceor(individual_book, place_term, places_paying):\n",
    "    \n",
    "    temp_df = pd.DataFrame(individual_book)\n",
    "    temp_df['minus1'] = temp_df.iloc[:,0] - 1\n",
    "    temp_df['dividebyterm'] = temp_df['minus1'] / place_term\n",
    "    temp_df['dividebyterm'] = temp_df['dividebyterm'] + 1\n",
    "    temp_df['placeor'] = 1/temp_df['dividebyterm']\n",
    "\n",
    "    o_r = round(temp_df['placeor'].sum(),2)\n",
    "    \n",
    "    if o_r < places_paying:\n",
    "        isgreen = True\n",
    "    else:\n",
    "        isgreen = False\n",
    "    \n",
    "    return isgreen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d73292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: URL\n",
    "# Output: Place terms and places paying for each bookie\n",
    "# Working okay, not fully tested\n",
    "\n",
    "def getEWTerms(url):\n",
    "    \n",
    "    book = [\"B3\", \"SK\", \"PP\", \"WH\", \"EE\", \"FB\", \"VC\", \"CE\", \"UN\", \"SX\", \"FR\", \"BY\", \"OE\", \"SA\", \"SI\", \"QN\", \"WA\", \"LD\"]\n",
    "\n",
    "    ids = [\"diff-row evTabRow bc\"]\n",
    "\n",
    "    scraper = cloudscraper.create_scraper(delay=10,browser={'custom': 'ScraperBot/1.0',})\n",
    "\n",
    "    url = url\n",
    "\n",
    "    req = scraper.get(url)\n",
    "    soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "\n",
    "    data = soup.find(\"tbody\", {\"id\": \"t1\"})\n",
    "    all_horses = soup.find_all(\"tr\", {\"class\": ids})\n",
    "    num_horses = len(all_horses)\n",
    "    \n",
    "    running_horses = []\n",
    "    i = 0\n",
    "    possible_nrs = 10\n",
    "    j = 0\n",
    "\n",
    "    while i < num_horses:\n",
    "        horse_name = all_horses[i]['data-bname']\n",
    "        running_horses.append(horse_name)\n",
    "        i+=1\n",
    "\n",
    "    while j < possible_nrs:\n",
    "        num = \"nr\"\n",
    "        running_horses.append(num)\n",
    "        j+=1\n",
    "\n",
    "    # b365 = data.find_all(\"td\", {\"data-bk\": \"B3\"})\n",
    "\n",
    "\n",
    "    # place_term = b365[0]['data-ew-denom']\n",
    "    # places_paying = b365[0]['data-ew-places']\n",
    "\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    df['horse'] = running_horses\n",
    "\n",
    "    gem = 0\n",
    "\n",
    "    place_terms = []\n",
    "    places_paying = []\n",
    "    \n",
    "    try:\n",
    "        while gem < len(book):\n",
    "            bookie = data.find_all(\"td\", {\"data-bk\": book[gem]})\n",
    "\n",
    "            place_term = bookie[0]['data-ew-denom']\n",
    "            place_paying = bookie[0]['data-ew-places']\n",
    "\n",
    "            place_term = int(place_term)\n",
    "            place_paying = int(place_paying)\n",
    "\n",
    "            place_terms.append(place_term)\n",
    "            places_paying.append(place_paying)\n",
    "\n",
    "            gem+=1\n",
    "\n",
    "        dfnew = pd.DataFrame(columns=[book])\n",
    "\n",
    "        dfnew.loc[0] = place_terms\n",
    "        dfnew.loc[1] = places_paying\n",
    "\n",
    "        dfnew.rename(index={0: 'PlaceTerms', 1: 'PlacesPaying'}, inplace=True)\n",
    "    \n",
    "        return dfnew\n",
    "    \n",
    "    except:\n",
    "        print(\"Error: place terms not found -\", url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61579b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: URL\n",
    "# Output: Boolean (T/F) whether any bookie offers green E/W\n",
    "\n",
    "\n",
    "def checkGreen(url):\n",
    "    \n",
    "    book = [\"B3\", \"SK\", \"PP\", \"WH\", \"EE\", \"FB\", \"VC\", \"CE\", \"UN\", \"SX\", \"FR\", \"BY\", \"OE\", \"SA\", \"SI\", \"QN\", \"WA\", \"LD\"]\n",
    "\n",
    "    dfew = getEWTerms(url)\n",
    "\n",
    "    df = getTable(url)\n",
    "\n",
    "    df = df.drop(columns='horse')\n",
    "\n",
    "    total_bookies = df.shape[1]\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    green_list = []\n",
    "    \n",
    "    try:\n",
    "\n",
    "        while i < total_bookies:\n",
    "\n",
    "            df[book] = df[book].apply(pd.to_numeric)\n",
    "            individual_book = df.iloc[:,i]\n",
    "\n",
    "            placeterm = dfew.iloc[0,i]\n",
    "            placespaying = dfew.iloc[1,i]\n",
    "\n",
    "            colour = getPlaceor(individual_book, placeterm, placespaying)\n",
    "\n",
    "            green_list.append(colour)\n",
    "\n",
    "            i+=1\n",
    "\n",
    "        isgreen = any(i == True for i in green_list)\n",
    "\n",
    "        return isgreen\n",
    "    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterLinks(string, substr):\n",
    "    return [str for str in string if\n",
    "            any(sub in str for sub in substr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8914c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinks():\n",
    "    \n",
    "    racecourses = pd.read_csv('racecourses.txt', sep=\",\", header=None)[0].tolist() \n",
    "    \n",
    "    links = []\n",
    "\n",
    "    scraper = cloudscraper.create_scraper(delay=10,browser={'custom': 'ScraperBot/1.0',})\n",
    "\n",
    "    url = \"https://www.oddschecker.com/horse-racing/\"\n",
    "\n",
    "    page = scraper.get(url)    \n",
    "    data = page.text\n",
    "    soup = BeautifulSoup(data)\n",
    "\n",
    "    for link in soup.find_all('a'):\n",
    "        links.append(link.get('href'))\n",
    "\n",
    "    links1 = []\n",
    "    for val in links:\n",
    "        if val != None :\n",
    "            links1.append(val)\n",
    "\n",
    "    links2 = [k for k in links1 if 'winner' in k]\n",
    "\n",
    "    links3 = [k for k in links2 if '/horse-racing/' in k]\n",
    "\n",
    "    links4 = links3[:140]\n",
    "    \n",
    "    urls = links4\n",
    "    \n",
    "    urls = [f\"https://www.oddschecker.com{l}\"for l in urls]\n",
    "    \n",
    "    urls = filterLinks(urls, racecourses)\n",
    "    \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d033edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_triu1(df):          \n",
    "    a = df.values\n",
    "    r,c = np.triu_indices(a.shape[1],1)\n",
    "    cols = df.columns\n",
    "    nm = [cols[i]+\"_\"+cols[j] for i,j in zip(r,c)]\n",
    "    return pd.DataFrame(a[:,r] - a[:,c], columns=nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d03241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkMP(url, MP_THRESHOLD):\n",
    "\n",
    "    MP_THRESHOLD = 0.08 # Set this to whatever you want (0.07 = 7%)\n",
    "\n",
    "    url = url\n",
    "\n",
    "    book = [\"B3\", \"SK\", \"PP\", \"WH\", \"EE\", \"FB\", \"VC\", \"CE\", \"UN\", \"SX\", \"FR\", \"BY\", \"OE\", \"SA\", \"SI\", \"QN\", \"WA\", \"LD\"]\n",
    "\n",
    "    df = getTable(url)\n",
    "    df = df.drop(columns='horse')\n",
    "    total_bookies = df.shape[1]\n",
    "\n",
    "    df = df.astype(float)\n",
    "\n",
    "    df_percent = df.pow(-1).round(2)\n",
    "\n",
    "\n",
    "    df_percent.replace([np.inf, -np.inf], 0.00, inplace=True)\n",
    "\n",
    "    all_ov = list(df_percent.iloc[0:].sum())\n",
    "    books_open_asper = sum(x > 1 for x in all_ov) / len(all_ov)\n",
    "    b365 = all_ov[0]\n",
    "    pp = all_ov[2]\n",
    "\n",
    "    if books_open_asper > 0.5:\n",
    "        df_diff = numpy_triu1(df_percent)\n",
    "\n",
    "        df_diff = df_diff.abs()\n",
    "\n",
    "        a = list(df_diff.max())\n",
    "\n",
    "        max_diff = max(a)\n",
    "\n",
    "        ismp = max_diff > MP_THRESHOLD\n",
    "    else:\n",
    "        ismp = False\n",
    "\n",
    "        return ismp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb80c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2022','2023','2024']\n",
    "\n",
    "urls = getLinks()\n",
    "\n",
    "urls_tomorrow = filterLinks(urls, years)\n",
    "\n",
    "urls_today = [x for x in urls if x not in urls_tomorrow]\n",
    "\n",
    "races_to_check = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d8cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This filters out races that have already taken place\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = datetime.now()\n",
    "current_day = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "i=0\n",
    "urls_today_clean = []\n",
    "\n",
    "while i < len(urls_today):\n",
    "\n",
    "    time = re.search('/horse-racing/(.*)/winner', urls_today[i])\n",
    "    time = time.group(1)\n",
    "    time = time[-5:]\n",
    "    time = now.replace(hour=int(time[:2]), minute=int(time[-2:]))\n",
    "\n",
    "    if current_time < time:\n",
    "        urls_today_clean.append(urls_today[i])\n",
    "        i+=1\n",
    "    else:\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e5bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding cleaned today's urls to tomorrows to get all urls (clean)\n",
    "\n",
    "all_urls_clean = urls_today_clean + urls_tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea9b36",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this is the main driver of the project\n",
    "\n",
    "MP_THRESHOLD = 0.07 # Set this to whatever you want (0.07 = 7%)\n",
    "links_to_use = all_urls_clean # change this by desired races to scrape (all_urls_clean, urls_today_clean or urls_tomorrow)\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < len(links_to_use):\n",
    "    url = links_to_use[i]\n",
    "\n",
    "    arbcheck = checkArb(url)\n",
    "    greencheck = checkGreen(url)\n",
    "    #mpcheck = checkMP(url, MP_THRESHOLD)\n",
    "\n",
    "    if arbcheck or greencheck:# or mpcheck:\n",
    "        races_to_check.append(url)\n",
    "    else:\n",
    "        races_to_check\n",
    "    print(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b67ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_to_send = []\n",
    "k=0\n",
    "\n",
    "while k < len(races_to_check):\n",
    "    to_send = re.search('/horse-racing/(.*)/winner', races_to_check[k])\n",
    "    to_send = to_send.group(1)\n",
    "    to_send = to_send.replace('/',' ',1)\n",
    "    all_to_send.append(to_send)\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50395955",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_to_send = '<br>'.join(all_to_send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752f2284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this calculates time to scrape \n",
    "\n",
    "end_time = datetime.now()\n",
    "\n",
    "duration = end_time - start_time                         \n",
    "duration = divmod(duration.total_seconds(),60)\n",
    "mins = str(int(round(duration[0],0)))\n",
    "seconds = str(int(round(duration[1],0)))\n",
    "\n",
    "time_info = \"time_to_scan: \"+mins+\" minutes \"+seconds+\" seconds\"\n",
    "races_scanned = \"races_scanned: \"+str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e4c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "message_content= 'Hi,<br>The following races are worth looking at:<p><p>'+str(all_to_send)+'</p><p><p>Thanks,<br>1mikebot1</p><p></p>'+time_info+'</p><p>'+races_scanned+'<p>www.oddschecker.com/horse-racing<p>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23735fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_list = ['michael98mullin@gmail.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d389d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mailer\n",
    "number = randrange(100)\n",
    "\n",
    "message = Mail(\n",
    "    from_email='1mikebot1@gmail.com',\n",
    "    to_emails=email_list,\n",
    "    subject=\"Oddschecker (\"+current_day+\") #\"+str(number),\n",
    "    html_content=message_content)\n",
    "try:\n",
    "    sg = SendGridAPIClient(APIKEY)\n",
    "    response = sg.send(message)\n",
    "    print(response.status_code)\n",
    "    print(response.body)\n",
    "    print(response.headers)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "number+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
